install.packages("ragg")
install.packages("ragg")
install.packages("tidyverse")
install.packages("ragg")
install.packages("tidyverse")
print(as_tibble(tab), n = 5)
library("tidyverse")
tab <- read.csv("data/people.csv")
source("~/Documents/MUNI/MA012/explore_dataset.R", echo=TRUE)
print(as_tibble(tab), n = 5)
summary(tab)
# Usage:
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
bartlett.test(Weight ~ Variety, data = dat)
leveneTest(Weight ~ Variety, data = dat)
# Usage: Checks if for each group of Variety, the samples have same variance
library("car")
install.packages("car")
dat <- read.csv2(file = "data/potatoes.csv")
shapiro.test(Weight ~ Variety, data = dat)
shapiro.test(Weight, data = dat)
shapiro.test(Weight)
shapiro.test(dat$Weight)
# Usage: Checks if for each group of Variety, the samples have same variance
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
bartlett.test(Weight ~ Variety, data = dat)
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
leveneTest(Weight ~ Variety, data = dat)
# Usage: Checks if for each group of Variety, the samples have same variance
library("car")
install.package("car")
install.packages("car")
install.packages("SparseM")
install.packages("SparseM")
install.packages("minqa")
install.packages("nloptr")
install.packages("nloptr")
install.packages("RcppEigen")
install.packages("MatrixModels")
install.packages("lme4")
install.packages("pbkrtest")
install.packages("quantreg")
install.packages("car")
leveneTest(Weight ~ Variety, data = dat)
# Usage: Checks if for each group of Variety, the samples have same variance
library("car")
leveneTest(Weight ~ Variety, data = dat)
lillie.test(dat$Weight)$p.value, error = function (e) {return(NA)}
lillie.test(dat$Weight)$p.value
lillie.test(dat$Weight)
lillie.test(dat$Weight)
library("nortest")
install.packages("nortest")
dat <- read.csv2(file = "data/potatoes.csv")
lillie.test(dat$Weight)
library("nortest")
dat <- read.csv2(file = "data/potatoes.csv")
lillie.test(dat$Weight)
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
aov.model <- aov(Weight ~ Variety, data = dat) # aov object
summary(aov.model) # ANOVA table
head(dat)
str(dat)
aov.model <- aov(Weight ~ Variety, data = dat) # aov object
summary(aov.model) # ANOVA table
# Effects table
model.tables(aov.model, type = "effects")
# Means table
model.tables(aov.model, type = "means")
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
aov.model <- aov(Weight ~ Variety, data = dat) # aov object
summary(aov.model) # ANOVA table
TukeyTest <- TukeyHSD(aov.model)
TukeyTest
TukeyTest$Variety |>
as.data.frame() |>
rownames_to_column(var = "groups") |>
rename("p.value" = "p adj") |>
mutate(significant = factor(p.value < 0.05)) |>
ggplot(aes(x = groups, y = diff, ymin = lwr, ymax = upr, colour = significant)) +
geom_hline(yintercept = 0, color = "black", linetype = "dashed", linewidth = 0.5) +
geom_errorbar(width = 0.1) +
geom_point(size = 2) +
labs(x = "potato varieties", y = "difference in weights [kg]")
ScheffeTest
dat <- read.csv2(file = "data/potatoes.csv")
dat <- dat |>
mutate(Variety = factor(Variety))
aov.model <- aov(Weight ~ Variety, data = dat) # aov object
ScheffeTest <- scheffe.test(aov.model, "Variety")
ScheffeTest
library("agricolae")
library("car")
library("nortest")
scheffe.test
ScheffeTest <- scheffe.test(aov.model, "Variety")
ScheffeTest
ScheffeTest <- scheffe.test(aov.model, "Variety")
install.packages("agricolae")
ScheffeTest <- scheffe.test(aov.model, "Variety")
library("agricolae")
ScheffeTest <- scheffe.test(aov.model, "Variety")
ScheffeTest
dat <- read.csv2(file = "data/hay.csv")
dat <- dat |>
mutate(Soil = factor(Soil), Fertilizer = factor(Fertilizer))
aov.model <- aov(Yield ~ Soil + Fertilizer + Soil:Fertilizer, data = dat) # aov object
summary(aov.model) # ANOVA table
aov.models$Means
aov.models$effects
aov.models$Effects
model.tables(aov.model, type = "effects")
model.tables(aov.model, type = "means")
summary(aov.model) # ANOVA table
str(dat)
summary(aov.model) # ANOVA table
SIGN.test(dat$X, md = 60)
library("BSDA")
install.packages("BSDA")
library("BSDA")
dat <- read.csv2(file = "data/minute.csv", header = FALSE)
SIGN.test(dat$X, md = 60)
SIGN.test(dat$V1, md = 60)
dat <- read.csv2(file = "data/minute.csv", header = FALSE)
wilcox.test(dat$V1, md = 60)
wilcox.test(dat |> filter(Fertilizer == "A") |> pull(Yield), dat |> filter(Fertilizer == "B") |> pull(Yield))
dat <- read.csv2(file = "data/field.csv")
wilcox.test(dat |> filter(Fertilizer == "A") |> pull(Yield), dat |> filter(Fertilizer == "B") |> pull(Yield))
KWtest <- kruskal(dat$Weight, dat$Variety)
dat <- read.csv2(file = "data/potatoes.csv")
KWtest <- kruskal(dat$Weight, dat$Variety)
KWtest
dat <- read.csv2(file = "data/field.csv")
wilcox.test(dat |> filter(Fertilizer == "A") |> pull(Yield), dat |> filter(Fertilizer == "B") |> pull(Yield))
KWtest <- kruskal(dat$Weight, dat$Variety)
KWtest
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
tab.raw <- read.csv2(file = "data/families.csv")
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
q <- tab |> summarise(q = mean(n.j < 5)) |> pull(q)
tab |> mutate(test = n.j >= 5 * q)
tab
tab.raw <- read.csv2(file = "data/families.csv")
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
q <- tab |> summarise(q = mean(n.j < 5)) |> pull(q)
tab |> mutate(test = n.j >= 5 * q)
tab
chisq.test(tab$N.j, p = tab$p.j) # built-in function
chisq.test(tab$N.j, p = tab$p.j) # built-in function
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
quantile <- qchisq(0.95, df = k - 1)
data.frame(K, df = k - 1, quantile, p.value = 1 - pchisq(K, df = k - 1))
chisq.test(tab$N.j, p = tab$p.j) # built-in function
chisq.test(tab$N.j, p = tab$p.j) # built-in function
tab
source("~/Documents/MUNI/MA012/pearson-chi-squared.R")
tab.raw <- read.csv2(file = "data/families.csv")
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
q <- tab |> summarise(q = mean(n.j < 5)) |> pull(q)
tab |> mutate(test = n.j >= 5 * q)
tab
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
quantile <- qchisq(0.95, df = k - 1)
data.frame(K, df = k - 1, quantile, p.value = 1 - pchisq(K, df = k - 1))
chisq.test(tab$N.j, p = tab$p.j) # built-in function
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
quantile <- qchisq(0.95, df = k - 1)
data.frame(K, df = k - 1, quantile, p.value = 1 - pchisq(K, df = k - 1))
chisq.test(tab$N.j, p = tab$p.j) # built-in function
k <- nrow(tab)
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
quantile <- qchisq(0.95, df = k - 1)
data.frame(K, df = k - 1, quantile, p.value = 1 - pchisq(K, df = k - 1))
chisq.test(tab$N.j, p = tab$p.j) # built-in function
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
n <- tab.raw |> summarise(n = sum(NumFamilies)) |> pull(n)
tab <- tab.raw |> as_tibble() |> transmute(
x.j = NumBoys,
A.j = factor(NumBoys),
N.j = NumFamilies,
p.j = dbinom(NumBoys, size = 5, prob = 0.5),
n.j = n * p.j
)
q <- tab |> summarise(q = mean(n.j < 5)) |> pull(q)
tab |> mutate(test = n.j >= 5 * q)
tab
k <- nrow(tab)
K <- tab |> summarize(K = sum((N.j - n.j)^2 / n.j)) |> pull(K)
quantile <- qchisq(0.95, df = k - 1)
data.frame(K, df = k - 1, quantile, p.value = 1 - pchisq(K, df = k - 1))
chisq.test(tab$N.j, p = tab$p.j) # built-in function
source("~/Documents/MUNI/MA012/pearson-chi-squared.R")
# Pearson criterion
tab |> mutate(test = n.j >= 5)
tab
tab
source("~/Documents/MUNI/MA012/pearson-chi-squared.R")
source("~/Documents/MUNI/MA012/pearson-chi-squared.R")
chisq.test(tab$N.j, p = tab$p.j) # built-in function
source("~/Documents/MUNI/MA012/pearson-chi-squared.R")
ks.test(tab$time_restart, "pexp", rate = lambda)
tab <- read.csv(file = "data/restart.csv")
ks.test(tab$time_restart, "pexp", rate = lambda)
lambda <- 0.04
ks.test(tab$time_restart, "pexp", rate = lambda)
tab <- read.csv("data/people.csv")
tab <- tab |>
mutate(
across(where(is.character),
factor
))
test <- t.test(Height ~ Sex, data = tab, var.equal = TRUE)
test
t.test(Height ~ Sex, data = tab, var.equal = TRUE)
cor.test(dat$expense, dat$members)
cor.test(dat$expense, dat$members)
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5)
cor.test(dat$expense, dat$members)
cov(Z)
cor(Z)
Z <- as.matrix(dat)
cov(Z)
cor(Z)
cor.test(dat$expense, dat$members)
dat$expense
dat
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5)
dat
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
Z <- as.matrix(dat)
cov(Z)
cor(Z)
dat$expense
cor.test(dat$expense, dat$members)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
library("ggcorrplot")
install.packages("ggcorrplot")
library("ggcorrplot")
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
cor.test(dat$expense, dat$members)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
# Plot:
R <- rcorr(Z)
library("ppcor")
install.packages("ppcor")
# Plot:
R <- rcorr(Z)
# Method        : Pearson correlation
# What is it for: Check if there is a linear connection between the variables
# How to read   : P-value & if > 1, then there is positive, if < 1 then there is negative, if = 0, then there is none
library("ppcor")      # pcor
library("Hmisc")      # rcorr
library("tidyverse")
library("GGally")     # ggpairs
library("ggcorrplot") # ggcorrplot
library("gridExtra")  # grid.arrange
install.packages("ppcor")
install.packages("ppcor")
install.packages("Hmisc")      # rcorr
# Method        : Pearson correlation
# What is it for: Check if there is a linear connection between the variables
# How to read   : P-value & if > 1, then there is positive, if < 1 then there is negative, if = 0, then there is none
library("Hmisc")      # rcorr
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
cor.test(dat$expense, dat$members)
# Plot:
R <- rcorr(Z)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
# Plot:
R <- rcorr(Z)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
library("ggcorrplot")
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
cor.test(dat$expense, dat$members)
# Plot:
R <- rcorr(Z)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
R.partial <- pcor(Z)
library("ppcor")
R.partial <- pcor(Z)
plot2 <- ggcorrplot(R.partial$estimate, p.mat = R.partial$p.value, title = "Partial Pearson's correlations", lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot2
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
cor.test(dat$expense, dat$members)
# Plot:
Z <- as.matrix(dat)
R <- rcorr(Z)
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
# Plot:
Z <- as.matrix(dat)
R <- rcorr(Z)
R
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
diag(R$P) <- 0
plot1 <- ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
plot1
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
# Method        : Spearman correlation
# What is it for: Check if there is a linear connection between the variables
# How to read   : P-value & if > 1, then there is positive, if < 1 then there is negative, if = 0, then there is none
library("Hmisc")      # rcorr
library("ggcorrplot")
library("ppcor")
dat <- read.csv2("data/households.csv", header = TRUE, skip = 5) |>
rename("members" = "N", "income" = "I", "expense" = "E")
cor.test(dat$expense, dat$members)
# Plot:
Z <- as.matrix(dat)
R <- rcorr(Z, type = "spearman")
diag(R$P) <- 0
ggcorrplot(R$r, p.mat = R$P, title = "Spearman's correlations",
lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
dat <- read.csv("data/people2.csv", stringsAsFactors = TRUE)
m1 <- lm(Weight ~ 1 + Height, data = dat)
# Coefficients
(beta <- coef(m1)) # L-S estimates of betas
# Confidence intervals
(beta.CI <- confint(m1)) # confidence intervals
dat <- read.csv2(file = "data/minute.csv", header = FALSE)
SIGN.test(dat$V1, md = 60)
test_statistic = (N_PLUS - (N / 2)) / sqrt(N / 4)
# Hands on:
N_PLUS = 11
N = 27
test_statistic = (N_PLUS - (N / 2)) / sqrt(N / 4)
test_statistic
quantile = qnorm(1 - test_statistic)
test_statistic
quantile = qnorm(1 - test_statistic)
test_statistic
test_statistic$1
test_statistic[1]
quantile = qnorm(1 - test_statistic[1])
quantile = qnorm(1 - (N_PLUS - (N / 2)) / sqrt(N / 4))
quantile = qnorm(1 - test_statistic/ 2)
test_statistic /2
1 - test_statistic
alpha = (N_PLUS - (N / 2)) / sqrt(N / 4)
alpha
quantile = qnorm(1 - alpha)
alpha
quantile = qnorm(1 - abs(alpha))
quantile
quantile = qnorm(1 - abs(alpha / 2))
quantile
alpha
quantile = qnorm(1 - (alpha / 2)
quantile = qnorm(1 - (alpha / 2)
alpha
quantile = qnorm(1 - (alpha / 2)
quantile = qnorm(1 - (alpha / 2))
quantile
quantile = qnorm(abs(alpha)
quantile
quantile = qnorm(abs(alpha))
quantile
alpha
quantile = qnorm(1 -abs(alpha))
quantile
p_value <- 2 * (1 - pnorm(abs(Z_value)))
p_value <- 2 * (1 - pnorm(abs(Z)))
2 * (1 - pnorm(abs(Z)))
2 * (1 - pnorm(abs(Z)))
Z
Z = (N_PLUS - (N / 2)) / sqrt(N / 4)
# Hands on:
N_PLUS = 11
N = 27
Z = (N_PLUS - (N / 2)) / sqrt(N / 4)
Z
2 * (1 - pnorm(abs(Z)))
2 * (1 - qnorm(abs(Z)))
norm(Z_value)
norm(Z)
norm(Z)
pnorm(Z)
2 * (1 - pnorm(abs(Z)))
X <- c(1, 2, 3, 4, 5)
Y <- c(5, 6, 7, 8, 7)
cor(X, Y, method = "kendall")
# Hands-on:
count_concordant_discordant(X, Y)
discordant <- 0
count_concordant_discordant <- function(X, Y) {
concordant <- 0
discordant <- 0
n <- length(X)
# Iterate over each unique pair of points (X[i], Y[i]) and (X[j], Y[j])
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
# Calculate the difference for each pair in both X and Y
diff_X <- X[i] - X[j]
diff_Y <- Y[i] - Y[j]
# Check if the pair is concordant or discordant
if (diff_X * diff_Y > 0) {
concordant <- concordant + 1
} else if (diff_X * diff_Y < 0) {
discordant <- discordant + 1
}
# Ties are ignored in concordant and discordant counts
}
}
# Return the counts as a list
return(list(concordant = concordant, discordant = discordant))
}
# Hands-on:
count_concordant_discordant(X, Y)
count_concordant_discordant <- function(X, Y) {
concordant <- 0
discordant <- 0
n <- length(X)
# Iterate over each unique pair of points (X[i], Y[i]) and (X[j], Y[j])
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
# Calculate the difference for each pair in both X and Y
diff_X <- X[i] - X[j]
diff_Y <- Y[i] - Y[j]
# Check if the pair is concordant or discordant
if (diff_X * diff_Y > 0) {
concordant <- concordant + 1
} else if (diff_X * diff_Y < 0) {
discordant <- discordant + 1
}
# Ties are ignored in concordant and discordant counts
}
}
# Return the counts as a list
return(list(C = concordant, D = discordant))
}
# Hands-on:
res <- count_concordant_discordant(X, Y)
C = res$C
D = res$D
t = (C - D) / (1/2 * n * (n - 1))
t
X <- c(2,4,6,8)
Y <- c(1,3,5,7)
cor(X, Y, method = "kendall")
# Hands-on:
res <- count_concordant_discordant(X, Y)
C = res$C
D = res$D
t = (C - D) / (1/2 * n * (n - 1))
t
C = res$C
D = res$D
t, C, D
C
D
n = 4
t = (C - D) / (1/2 * n * (n - 1))
t
